{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abecid/deepest-quest/blob/main/colab/NLP_Quest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c7d5b5c3",
      "metadata": {
        "id": "c7d5b5c3"
      },
      "outputs": [],
      "source": [
        "# NLP Quest\n",
        "\n",
        "## Summary\n",
        "    # 1. Trasformer\n",
        "    # 2. Data Normalization\n",
        "    # 3. MLP (Classification)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Data\n",
        "train_data_path = '/Users/adamlee/Downloads/Deepest/deepest-quest/2023-Spring/NLP/data/utkmls-twitter-spam-detection-competition/train.csv'\n",
        "test_data_path = '/Users/adamlee/Downloads/Deepest/deepest-quest/2023-Spring/NLP/data/utkmls-twitter-spam-detection-competition/test.csv'\n",
        "\n",
        "train_data_path = 'https://raw.githubusercontent.com/Abecid/deepest-quest/main/2023-Spring/NLP/data/utkmls-twitter-spam-detection-competition/train.csv'\n",
        "test_data_path = 'https://raw.githubusercontent.com/Abecid/deepest-quest/main/2023-Spring/NLP/data/utkmls-twitter-spam-detection-competition/test.csv'\n",
        "\n",
        "# train_data = pd.read_csv(train_data_path).drop(columns=['following', 'followers', 'actions', 'is_retweet', 'location'])\n",
        "# test_data = pd.read_csv(test_data_path).drop(columns=['following', 'followers', 'actions', 'is_retweet', 'location'])\n",
        "\n",
        "train_data = pd.read_csv(train_data_path)[[\"Tweet\", \"Type\"]]\n",
        "test_data = pd.read_csv(test_data_path)[[\"Tweet\"]]\n",
        "\n",
        "# 0: Quality, 1: Spam\n",
        "train_data['Type'] = train_data['Type'].map({'Quality': 0, 'Spam': 1})\n",
        "\n",
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "pKGRAOmoCvYa",
        "outputId": "19d74a0c-44e7-4fd7-9cb8-b02379fab9bd"
      },
      "id": "pKGRAOmoCvYa",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   Tweet  Type\n",
              "0                         Good Morning Love  @LeeBrown_V   0.0\n",
              "1               '@realDonaldTrump @USNavy RIP TO HEROES'   1.0\n",
              "2      Haven't been following the news but I understa...   0.0\n",
              "3      pic.twitter.com/dy9q4ftLhZ What to do with pap...   0.0\n",
              "4      #DidYouKnow ► Mahatma Gandhi made a brief visi...   0.0\n",
              "...                                                  ...   ...\n",
              "14894  #AllWentWrongWhen I told my hair stylist to \"g...   1.0\n",
              "14895  They don't have to like you, and you don't hav...   0.0\n",
              "14896  #Miami Graham Nash Live at Parker Playhouse  #...   1.0\n",
              "14897  @bethannhamilton is in the business of one-upp...   0.0\n",
              "14898    Chasing Success  by  Space Cadetz  Listen up...   1.0\n",
              "\n",
              "[14899 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3a722cce-99f6-4a9e-90a2-7d612677c7a9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Good Morning Love  @LeeBrown_V</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>'@realDonaldTrump @USNavy RIP TO HEROES'</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Haven't been following the news but I understa...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>pic.twitter.com/dy9q4ftLhZ What to do with pap...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>#DidYouKnow ► Mahatma Gandhi made a brief visi...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14894</th>\n",
              "      <td>#AllWentWrongWhen I told my hair stylist to \"g...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14895</th>\n",
              "      <td>They don't have to like you, and you don't hav...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14896</th>\n",
              "      <td>#Miami Graham Nash Live at Parker Playhouse  #...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14897</th>\n",
              "      <td>@bethannhamilton is in the business of one-upp...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14898</th>\n",
              "      <td>Chasing Success  by  Space Cadetz  Listen up...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14899 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3a722cce-99f6-4a9e-90a2-7d612677c7a9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3a722cce-99f6-4a9e-90a2-7d612677c7a9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3a722cce-99f6-4a9e-90a2-7d612677c7a9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "VP3to-9_GA_y",
        "outputId": "d5b12f7f-5c4c-430b-cc40-c28614b077a6"
      },
      "id": "VP3to-9_GA_y",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 Tweet\n",
              "0    Cops shoot blacks almost everyday, and there a...\n",
              "1    #HAPPYTAEYANGDAY  Oppa,happy birthday to you, ...\n",
              "2    RT @HoneyBadger10: Panthers in the super bowl....\n",
              "3    Sorry my Twitter keeps posting my retweets a m...\n",
              "4    Heart attack causes and symptoms are different...\n",
              "..                                                 ...\n",
              "780  New Project For NLex Please @DreamscapePH @abs...\n",
              "781  Actor DiCaprio joins growing movement to dives...\n",
              "782  Just overheard 'looping in' 'reaching out' and...\n",
              "783  Photoshoot time! #music #band #photoshootpic.t...\n",
              "784  Tony Starks N Peanut....Destiny.mp3 by tinomac...\n",
              "\n",
              "[785 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-96817381-568f-43b1-8a9c-a971e79041e1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Cops shoot blacks almost everyday, and there a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>#HAPPYTAEYANGDAY  Oppa,happy birthday to you, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RT @HoneyBadger10: Panthers in the super bowl....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sorry my Twitter keeps posting my retweets a m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Heart attack causes and symptoms are different...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>780</th>\n",
              "      <td>New Project For NLex Please @DreamscapePH @abs...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>781</th>\n",
              "      <td>Actor DiCaprio joins growing movement to dives...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>782</th>\n",
              "      <td>Just overheard 'looping in' 'reaching out' and...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>783</th>\n",
              "      <td>Photoshoot time! #music #band #photoshootpic.t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>784</th>\n",
              "      <td>Tony Starks N Peanut....Destiny.mp3 by tinomac...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>785 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-96817381-568f-43b1-8a9c-a971e79041e1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-96817381-568f-43b1-8a9c-a971e79041e1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-96817381-568f-43b1-8a9c-a971e79041e1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "sns.countplot(x = train_data[\"Type\"], data = train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "QvSk6HWuIXTt",
        "outputId": "e11aeb10-715c-43a6-9540-21727dae7d14"
      },
      "id": "QvSk6HWuIXTt",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='Type', ylabel='count'>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.models import XLMR_BASE_ENCODER\n",
        "from sklearn.model_selection import train_test_split\n",
        "import copy\n",
        "\n",
        "# Split the data into training and testing sets with a 70/30 split\n",
        "train_df, val_df = train_test_split(train_data, test_size=0.2, random_state=42)\n",
        "\n",
        "train_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "rztlRmHJRHro",
        "outputId": "bad2ac53-221b-442a-b2a1-9399eabd6987"
      },
      "id": "rztlRmHJRHro",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   Tweet  Type\n",
              "1891   Guys! Check out my playlist and new single #DU...   0.0\n",
              "2996   #StopPoliceViolence #StopPoliceBrutality #Stop...   1.0\n",
              "7341            Biology exam went better than I expected   0.0\n",
              "12802  We are proud to be part of this study!https://...   0.0\n",
              "4043   IBM's optical storage is 50 times faster than ...   0.0\n",
              "...                                                  ...   ...\n",
              "5191   The amended #aqabiology specificationpic.twitt...   0.0\n",
              "13418  We fail in people management when we do only I...   0.0\n",
              "5390   #TrumpSlide coming to restore America! I can't...   1.0\n",
              "860    '@johncardillo @realDonaldTrump https://t.co/I...   1.0\n",
              "7270   Spotify Has 20 Million Paid Subscribers http:/...   1.0\n",
              "\n",
              "[11919 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-999b8c0b-2ca8-44dc-b917-3f8c724e06f4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1891</th>\n",
              "      <td>Guys! Check out my playlist and new single #DU...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2996</th>\n",
              "      <td>#StopPoliceViolence #StopPoliceBrutality #Stop...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7341</th>\n",
              "      <td>Biology exam went better than I expected</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12802</th>\n",
              "      <td>We are proud to be part of this study!https://...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4043</th>\n",
              "      <td>IBM's optical storage is 50 times faster than ...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5191</th>\n",
              "      <td>The amended #aqabiology specificationpic.twitt...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13418</th>\n",
              "      <td>We fail in people management when we do only I...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5390</th>\n",
              "      <td>#TrumpSlide coming to restore America! I can't...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>860</th>\n",
              "      <td>'@johncardillo @realDonaldTrump https://t.co/I...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7270</th>\n",
              "      <td>Spotify Has 20 Million Paid Subscribers http:/...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11919 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-999b8c0b-2ca8-44dc-b917-3f8c724e06f4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-999b8c0b-2ca8-44dc-b917-3f8c724e06f4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-999b8c0b-2ca8-44dc-b917-3f8c724e06f4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.auroria.io/nlp-disaster-tweet-text-classification-roberta-pytorch/\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "import string\n",
        "\n",
        "class TweetDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer):\n",
        "        texts = dataframe.Tweet.values.tolist()\n",
        "\n",
        "        texts = [self._preprocess(text) for text in texts]\n",
        "\n",
        "        self._print_random_samples(texts)\n",
        "\n",
        "        self.texts = [tokenizer(text, padding='max_length',\n",
        "                                max_length=150,\n",
        "                                truncation=True,\n",
        "                                return_tensors=\"pt\")\n",
        "                      for text in texts]\n",
        "\n",
        "        if 'Type' in dataframe:\n",
        "            classes = dataframe.Type.values.tolist()\n",
        "            self.labels = classes\n",
        "\n",
        "    def _print_random_samples(self, texts):\n",
        "        np.random.seed(42)\n",
        "        random_entries = np.random.randint(0, len(texts), 5)\n",
        "\n",
        "        for i in random_entries:\n",
        "            print(f\"Entry {i}: {texts[i]}\")\n",
        "\n",
        "        print()\n",
        "\n",
        "    def _preprocess(self, text):\n",
        "        text = self._remove_amp(text)\n",
        "        text = self._remove_links(text)\n",
        "        text = self._remove_hashes(text)\n",
        "        text = self._remove_retweets(text)\n",
        "        text = self._remove_mentions(text)\n",
        "        text = self._remove_multiple_spaces(text)\n",
        "\n",
        "        #text = self._lowercase(text)\n",
        "        text = self._remove_punctuation(text)\n",
        "        # text = self._remove_numbers(text)\n",
        "\n",
        "        text_tokens = self._tokenize(text)\n",
        "        text_tokens = self._stopword_filtering(text_tokens)\n",
        "        # text_tokens = self._stemming(text_tokens)\n",
        "        text = self._stitch_text_tokens_together(text_tokens)\n",
        "\n",
        "        return text.strip()\n",
        "\n",
        "\n",
        "    def _remove_amp(self, text):\n",
        "        return text.replace(\"&amp;\", \" \")\n",
        "\n",
        "    def _remove_mentions(self, text):\n",
        "        return re.sub(r'(@.*?)[\\s]', ' ', text)\n",
        "    \n",
        "    def _remove_multiple_spaces(self, text):\n",
        "        return re.sub(r'\\s+', ' ', text)\n",
        "\n",
        "    def _remove_retweets(self, text):\n",
        "        return re.sub(r'^RT[\\s]+', ' ', text)\n",
        "\n",
        "    def _remove_links(self, text):\n",
        "        return re.sub(r'https?:\\/\\/[^\\s\\n\\r]+', ' ', text)\n",
        "\n",
        "    def _remove_hashes(self, text):\n",
        "        return re.sub(r'#', ' ', text)\n",
        "\n",
        "    def _stitch_text_tokens_together(self, text_tokens):\n",
        "        return \" \".join(text_tokens)\n",
        "\n",
        "    def _tokenize(self, text):\n",
        "        return nltk.word_tokenize(text, language=\"english\")\n",
        "\n",
        "    def _stopword_filtering(self, text_tokens):\n",
        "        stop_words = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "        return [token for token in text_tokens if token not in stop_words]\n",
        "\n",
        "    def _stemming(self, text_tokens):\n",
        "        porter = nltk.stem.porter.PorterStemmer()\n",
        "        return [porter.stem(token) for token in text_tokens]\n",
        "\n",
        "    def _remove_numbers(self, text):\n",
        "        return re.sub(r'\\d+', ' ', text)\n",
        "\n",
        "    def _lowercase(self, text):\n",
        "        return text.lower()\n",
        "\n",
        "    def _remove_punctuation(self, text):\n",
        "        return ''.join(character for character in text if character not in string.punctuation)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "\n",
        "        label = -1\n",
        "        if hasattr(self, 'labels'):\n",
        "            label = self.labels[idx]\n",
        "\n",
        "        return text, label"
      ],
      "metadata": {
        "id": "b2VvFlItZvQ0"
      },
      "id": "b2VvFlItZvQ0",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model\n",
        "from torch import nn\n",
        "\n",
        "class TweetClassifier(nn.Module):\n",
        "    def __init__(self, base_model):\n",
        "        super(TweetClassifier, self).__init__()\n",
        "\n",
        "        self.bert = base_model\n",
        "        self.fc1 = nn.Linear(768, 32)\n",
        "        self.fc2 = nn.Linear(32, 1)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        bert_out = self.bert(input_ids=input_ids,\n",
        "                             attention_mask=attention_mask)[0][:, 0]\n",
        "        x = self.fc1(bert_out)\n",
        "        x = self.relu(x)\n",
        "        \n",
        "        x = self.fc2(x)\n",
        "        x = self.sigmoid(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "1BT6aasTKgvW"
      },
      "id": "1BT6aasTKgvW",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.optim import Adam\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train(model, train_dataloader, val_dataloader, learning_rate, epochs):\n",
        "    best_val_loss = float('inf')\n",
        "    early_stopping_threshold_count = 5\n",
        "    \n",
        "    \n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    model = model.to(device)\n",
        "    criterion = criterion.to(device)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_acc_train = 0\n",
        "        total_loss_train = 0\n",
        "        \n",
        "        model.train()\n",
        "        \n",
        "        for train_input, train_label in tqdm(train_dataloader):\n",
        "            attention_mask = train_input['attention_mask'].to(device)\n",
        "            input_ids = train_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "            train_label = train_label.to(device)\n",
        "\n",
        "            output = model(input_ids, attention_mask)\n",
        "\n",
        "            loss = criterion(output, train_label.float().unsqueeze(1))\n",
        "\n",
        "            total_loss_train += loss.item()\n",
        "\n",
        "            acc = ((output >= 0.5).int() == train_label.unsqueeze(1)).sum().item()\n",
        "            total_acc_train += acc\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            total_acc_val = 0\n",
        "            total_loss_val = 0\n",
        "            \n",
        "            model.eval()\n",
        "            \n",
        "            for val_input, val_label in tqdm(val_dataloader):\n",
        "                attention_mask = val_input['attention_mask'].to(device)\n",
        "                input_ids = val_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "                val_label = val_label.to(device)\n",
        "\n",
        "                output = model(input_ids, attention_mask)\n",
        "\n",
        "                loss = criterion(output, val_label.float().unsqueeze(1))\n",
        "\n",
        "                total_loss_val += loss.item()\n",
        "\n",
        "                acc = ((output >= 0.5).int() == val_label.unsqueeze(1)).sum().item()\n",
        "                total_acc_val += acc\n",
        "            \n",
        "            print(f'Epochs: {epoch + 1} '\n",
        "                  f'| Train Loss: {total_loss_train / len(train_dataloader): .3f} '\n",
        "                  f'| Train Accuracy: {total_acc_train / (len(train_dataloader.dataset)): .3f} '\n",
        "                  f'| Val Loss: {total_loss_val / len(val_dataloader): .3f} '\n",
        "                  f'| Val Accuracy: {total_acc_val / len(val_dataloader.dataset): .3f}')\n",
        "            \n",
        "            if best_val_loss > total_loss_val:\n",
        "                best_val_loss = total_loss_val\n",
        "                torch.save(model, f\"best_model.pt\")\n",
        "                print(\"Saved model\")\n",
        "                early_stopping_threshold_count = 0\n",
        "            else:\n",
        "                early_stopping_threshold_count += 1\n",
        "                \n",
        "            if early_stopping_threshold_count >= 1:\n",
        "                print(\"Early stopping\")\n",
        "                break"
      ],
      "metadata": {
        "id": "eqaDCA4xa-gv"
      },
      "id": "eqaDCA4xa-gv",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "text = \"This is a sentence. This is another sentence.\"\n",
        "sentences = sent_tokenize(text)\n",
        "print(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4WLinxtcAou",
        "outputId": "0086192d-11a1-4779-a4a7-5b1aa25d3d72"
      },
      "id": "m4WLinxtcAou",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['This is a sentence.', 'This is another sentence.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnFSk1OlgWwc",
        "outputId": "aee3d5f9-f618-438a-e762-36e6b18b19e6"
      },
      "id": "lnFSk1OlgWwc",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Mar 24 08:50:06 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   28C    P0    42W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "\n",
        "batch_size = 8\n",
        "    \n",
        "BERT_MODEL = \"roberta-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL)\n",
        "base_model = AutoModel.from_pretrained(BERT_MODEL)\n",
        "\n",
        "train_dataloader = DataLoader(TweetDataset(train_df, tokenizer), batch_size=batch_size, shuffle=True, num_workers=12)\n",
        "val_dataloader = DataLoader(TweetDataset(val_df, tokenizer), batch_size=batch_size, num_workers=12)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hb_bnEGxbO2u",
        "outputId": "a5723172-2f87-4045-d977-5d87a7730424"
      },
      "id": "hb_bnEGxbO2u",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entry 7270: Yeah striped socks\n",
            "Entry 860: alis BOOM Trump ERASES Another Piece Obamas Failed Legacy lis\n",
            "Entry 5390: Lee Amendment Can Stop AFFH puts Washington bureaucrats charge local government\n",
            "Entry 5191: Now Playing Metro Boomin ft Drake Offset No Complaints gt\n",
            "Entry 11284: andris Satellite Imagery Suggests North Korea Preparing Submarine Missile Test\n",
            "\n",
            "Entry 860: miss …\n",
            "Entry 1294: Start record label via RT201\n",
            "Entry 1130: mom told u wake like 29283 times youre still laying suddenly comes roompictwittercomzVgcRm6dca\n",
            "Entry 1095: For talk much sucks easily handled Bernie sanders shes done trump 16 GOP candidates couldnt\n",
            "Entry 1638: Thinking getting new tires summer We lot different rebates going right Stop expire\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for train_input, train_label in (train_dataloader):\n",
        "    print(\"x:\", train_input, \"y:\", train_label)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZaaSMUHlW5P",
        "outputId": "c8633125-4bce-483a-ed71-68ba48284620"
      },
      "id": "9ZaaSMUHlW5P",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x: {'input_ids': tensor([[[    0, 29734,   101,  ...,     1,     1,     1]],\n",
            "\n",
            "        [[    0,  3750,   513,  ...,     1,     1,     1]],\n",
            "\n",
            "        [[    0, 21136,   188,  ...,     1,     1,     1]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[    0, 34002,  6645,  ...,     1,     1,     1]],\n",
            "\n",
            "        [[    0, 41597,   459,  ...,     1,     1,     1]],\n",
            "\n",
            "        [[    0, 14323, 17967,  ...,     1,     1,     1]]]), 'attention_mask': tensor([[[1, 1, 1,  ..., 0, 0, 0]],\n",
            "\n",
            "        [[1, 1, 1,  ..., 0, 0, 0]],\n",
            "\n",
            "        [[1, 1, 1,  ..., 0, 0, 0]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[1, 1, 1,  ..., 0, 0, 0]],\n",
            "\n",
            "        [[1, 1, 1,  ..., 0, 0, 0]],\n",
            "\n",
            "        [[1, 1, 1,  ..., 0, 0, 0]]])} y: tensor([0., 0., 1., 0., 0., 0., 1., 1.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = TweetClassifier(base_model)\n",
        "\n",
        "\n",
        "learning_rate = 1e-5\n",
        "epochs = 50\n",
        "train(model, train_dataloader, val_dataloader, learning_rate, epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "FGB7oZsolUHg",
        "outputId": "a00cb8f5-8d17-4194-fbdf-ac4662ade849"
      },
      "id": "FGB7oZsolUHg",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1490 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-707bc3055fe4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-9ebde829e5b6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, val_dataloader, learning_rate, epochs)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mtrain_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-282d82314c12>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         bert_out = self.bert(input_ids=input_ids,\n\u001b[0m\u001b[1;32m     17\u001b[0m                              attention_mask=attention_mask)[0][:, 0]\n\u001b[1;32m     18\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    843\u001b[0m         \u001b[0mhead_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m         embedding_output = self.embeddings(\n\u001b[0m\u001b[1;32m    846\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m             \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0membeddings\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mposition_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/dropout.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1250\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dropout probability has to be between 0 and 1, \"\u001b[0m \u001b[0;34m\"but got {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1252\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: philox_cuda_state for an unexpected CUDA generator used during capture. In regions captured by CUDA graphs, you may only use the default CUDA RNG generator on the device that's current when capture begins. If you need a non-default (user-supplied) generator, or a generator on another device, please file an issue."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "# https://pytorch.org/text/main/tutorials/sst2_classification_non_distributed.html\n",
        "\n",
        "import torch\n",
        "\n",
        "num_classes = 2\n",
        "input_dim = 768\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "from torchtext.models import RobertaClassificationHead, XLMR_BASE_ENCODER\n",
        "\n",
        "classifier_head = RobertaClassificationHead(num_classes=num_classes, input_dim=input_dim)\n",
        "model = XLMR_BASE_ENCODER.get_model(head=classifier_head)\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2_3JBNf3krr",
        "outputId": "ba095027-ed9e-44a0-a2f5-c6da7d8192c1"
      },
      "id": "j2_3JBNf3krr",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaModel(\n",
              "  (encoder): RobertaEncoder(\n",
              "    (transformer): TransformerEncoder(\n",
              "      (token_embedding): Embedding(250002, 768, padding_idx=1)\n",
              "      (layers): TransformerEncoder(\n",
              "        (layers): ModuleList(\n",
              "          (0): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout1): Dropout(p=0.1, inplace=False)\n",
              "            (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout1): Dropout(p=0.1, inplace=False)\n",
              "            (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout1): Dropout(p=0.1, inplace=False)\n",
              "            (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (3): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout1): Dropout(p=0.1, inplace=False)\n",
              "            (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (4): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout1): Dropout(p=0.1, inplace=False)\n",
              "            (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (5): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout1): Dropout(p=0.1, inplace=False)\n",
              "            (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (6): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout1): Dropout(p=0.1, inplace=False)\n",
              "            (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (7): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout1): Dropout(p=0.1, inplace=False)\n",
              "            (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (8): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout1): Dropout(p=0.1, inplace=False)\n",
              "            (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (9): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout1): Dropout(p=0.1, inplace=False)\n",
              "            (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (10): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout1): Dropout(p=0.1, inplace=False)\n",
              "            (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (11): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout1): Dropout(p=0.1, inplace=False)\n",
              "            (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (positional_embedding): PositionalEmbedding(\n",
              "        (embedding): Embedding(514, 768, padding_idx=1)\n",
              "      )\n",
              "      (embedding_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (head): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
              "    (activation_fn): ReLU()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchtext.functional as F\n",
        "from torch.optim import AdamW\n",
        "import torch.nn as nn\n",
        "\n",
        "learning_rate = 1e-5\n",
        "optim = AdamW(model.parameters(), lr=learning_rate)\n",
        "criteria = nn.CrossEntropyLoss()\n",
        "\n",
        "padding_idx = 1\n",
        "\n",
        "\n",
        "def train_step(input, target):\n",
        "    output = model(input)\n",
        "    loss = criteria(output, target)\n",
        "    optim.zero_grad()\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "\n",
        "\n",
        "def eval_step(input, target):\n",
        "    output = model(input)\n",
        "    loss = criteria(output, target).item()\n",
        "    return float(loss), (output.argmax(1) == target).type(torch.float).sum().item()\n",
        "\n",
        "\n",
        "def evaluate():\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "    counter = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in val_dataloader:\n",
        "            input = F.to_tensor(batch[\"token_ids\"], padding_value=padding_idx).to(DEVICE)\n",
        "            target = torch.tensor(batch[\"target\"]).to(DEVICE)\n",
        "            loss, predictions = eval_step(input, target)\n",
        "            total_loss += loss\n",
        "            correct_predictions += predictions\n",
        "            total_predictions += len(target)\n",
        "            counter += 1\n",
        "\n",
        "    return total_loss / counter, correct_predictions / total_predictions"
      ],
      "metadata": {
        "id": "wJLzKRBU3lV5"
      },
      "id": "wJLzKRBU3lV5",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 1\n",
        "\n",
        "for e in range(num_epochs):\n",
        "    for input, target in train_dataloader:\n",
        "        input = input['input_ids'].squeeze(1).to(device)\n",
        "        # input = F.to_tensor(batch[\"token_ids\"], padding_value=padding_idx).to(device)\n",
        "        target = torch.tensor(target).to(device)\n",
        "        train_step(input, target)\n",
        "\n",
        "    loss, accuracy = evaluate()\n",
        "    print(\"Epoch = [{}], loss = [{}], accuracy = [{}]\".format(e, loss, accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "DAHa15_76TVt",
        "outputId": "1f831b6e-d441-4ba9-f9d7-d7e02199fc3c"
      },
      "id": "DAHa15_76TVt",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-5e8bd958a308>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  target = torch.tensor(target).to(device)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-5e8bd958a308>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m# input = F.to_tensor(batch[\"token_ids\"], padding_value=padding_idx).to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-0098cdf66f24>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(input, target)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriteria\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1175\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                label_smoothing=self.label_smoothing)\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3024\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3025\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: \"nll_loss_forward_reduce_cuda_kernel_2d_index\" not implemented for 'Double'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "okQ9yzkfKijt"
      },
      "id": "okQ9yzkfKijt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1OgKLYbtKjcy"
      },
      "id": "1OgKLYbtKjcy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "450bd428",
      "metadata": {
        "id": "450bd428"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class TwitterSpamDetector(nn.Module):\n",
        "    def __init__(self, num_tokens, emb_size, num_heads, hidden_size, num_layers, dropout_prob, num_following, num_followers, num_actions):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding(num_tokens, emb_size)\n",
        "        \n",
        "        # Transformer encoder\n",
        "        self.encoder_layer = nn.TransformerEncoderLayer(emb_size, num_heads, hidden_size, dropout_prob)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers)\n",
        "        \n",
        "        # MLP layers\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(emb_size + num_following + num_followers + num_actions + 1, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 2)\n",
        "        )\n",
        "\n",
        "        self.num_following = num_following\n",
        "        self.num_followers = num_followers\n",
        "        self.num_actions = num_actions\n",
        "        \n",
        "    def forward(self, x, following, followers, actions, is_retweet):\n",
        "        # Encode input sequence with Transformer\n",
        "        x = self.embedding(x)\n",
        "        x = self.transformer_encoder(x)\n",
        "\n",
        "        # Concatenate normalized input values\n",
        "        following_norm = following.float()\n",
        "        followers_norm = followers.float()\n",
        "        actions_norm = actions.float()\n",
        "        is_retweet = is_retweet.float()\n",
        "        input_vec = torch.cat([x.mean(dim=1), following_norm.unsqueeze(1), followers_norm.unsqueeze(1), actions_norm.unsqueeze(1), is_retweet.unsqueeze(1)], dim=1)\n",
        "\n",
        "        # Pass through MLP layers\n",
        "        y = self.mlp(input_vec)\n",
        "\n",
        "        return y\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}