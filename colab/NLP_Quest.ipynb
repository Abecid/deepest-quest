{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abecid/deepest-quest/blob/main/colab/NLP_Quest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c7d5b5c3",
      "metadata": {
        "id": "c7d5b5c3"
      },
      "outputs": [],
      "source": [
        "# NLP Quest\n",
        "\n",
        "## Summary\n",
        "    # 1. Trasformer\n",
        "    # 2. Data Normalization\n",
        "    # 3. MLP (Classification)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Data\n",
        "train_data_path = '/Users/adamlee/Downloads/Deepest/deepest-quest/2023-Spring/NLP/data/utkmls-twitter-spam-detection-competition/train.csv'\n",
        "test_data_path = '/Users/adamlee/Downloads/Deepest/deepest-quest/2023-Spring/NLP/data/utkmls-twitter-spam-detection-competition/test.csv'\n",
        "\n",
        "train_data_path = 'https://raw.githubusercontent.com/Abecid/deepest-quest/main/2023-Spring/NLP/data/utkmls-twitter-spam-detection-competition/train.csv'\n",
        "test_data_path = 'https://raw.githubusercontent.com/Abecid/deepest-quest/main/2023-Spring/NLP/data/utkmls-twitter-spam-detection-competition/test.csv'\n",
        "\n",
        "# train_data = pd.read_csv(train_data_path).drop(columns=['following', 'followers', 'actions', 'is_retweet', 'location'])\n",
        "# test_data = pd.read_csv(test_data_path).drop(columns=['following', 'followers', 'actions', 'is_retweet', 'location'])\n",
        "\n",
        "train_data = pd.read_csv(train_data_path)[[\"Tweet\", \"Type\"]]\n",
        "test_data = pd.read_csv(test_data_path)[[\"Tweet\"]]\n",
        "\n",
        "# 0: Quality, 1: Spam\n",
        "train_data['Type'] = train_data['Type'].map({'Quality': 0, 'Spam': 1})\n",
        "\n",
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "pKGRAOmoCvYa",
        "outputId": "85649f58-b664-4f6c-ce6c-08573f5ccca5"
      },
      "id": "pKGRAOmoCvYa",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   Tweet  Type\n",
              "0                         Good Morning Love  @LeeBrown_V   0.0\n",
              "1               '@realDonaldTrump @USNavy RIP TO HEROES'   1.0\n",
              "2      Haven't been following the news but I understa...   0.0\n",
              "3      pic.twitter.com/dy9q4ftLhZ What to do with pap...   0.0\n",
              "4      #DidYouKnow ► Mahatma Gandhi made a brief visi...   0.0\n",
              "...                                                  ...   ...\n",
              "14894  #AllWentWrongWhen I told my hair stylist to \"g...   1.0\n",
              "14895  They don't have to like you, and you don't hav...   0.0\n",
              "14896  #Miami Graham Nash Live at Parker Playhouse  #...   1.0\n",
              "14897  @bethannhamilton is in the business of one-upp...   0.0\n",
              "14898    Chasing Success  by  Space Cadetz  Listen up...   1.0\n",
              "\n",
              "[14899 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-49964eb6-7fbb-4755-90b0-fc87b607eda0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Good Morning Love  @LeeBrown_V</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>'@realDonaldTrump @USNavy RIP TO HEROES'</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Haven't been following the news but I understa...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>pic.twitter.com/dy9q4ftLhZ What to do with pap...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>#DidYouKnow ► Mahatma Gandhi made a brief visi...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14894</th>\n",
              "      <td>#AllWentWrongWhen I told my hair stylist to \"g...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14895</th>\n",
              "      <td>They don't have to like you, and you don't hav...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14896</th>\n",
              "      <td>#Miami Graham Nash Live at Parker Playhouse  #...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14897</th>\n",
              "      <td>@bethannhamilton is in the business of one-upp...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14898</th>\n",
              "      <td>Chasing Success  by  Space Cadetz  Listen up...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14899 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-49964eb6-7fbb-4755-90b0-fc87b607eda0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-49964eb6-7fbb-4755-90b0-fc87b607eda0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-49964eb6-7fbb-4755-90b0-fc87b607eda0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "VP3to-9_GA_y",
        "outputId": "f780fed5-62ef-451d-dee2-ddb403b21c88"
      },
      "id": "VP3to-9_GA_y",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 Tweet\n",
              "0    Cops shoot blacks almost everyday, and there a...\n",
              "1    #HAPPYTAEYANGDAY  Oppa,happy birthday to you, ...\n",
              "2    RT @HoneyBadger10: Panthers in the super bowl....\n",
              "3    Sorry my Twitter keeps posting my retweets a m...\n",
              "4    Heart attack causes and symptoms are different...\n",
              "..                                                 ...\n",
              "780  New Project For NLex Please @DreamscapePH @abs...\n",
              "781  Actor DiCaprio joins growing movement to dives...\n",
              "782  Just overheard 'looping in' 'reaching out' and...\n",
              "783  Photoshoot time! #music #band #photoshootpic.t...\n",
              "784  Tony Starks N Peanut....Destiny.mp3 by tinomac...\n",
              "\n",
              "[785 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-661ef3e9-493b-41b8-8ad3-a5f1d8138e1b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Cops shoot blacks almost everyday, and there a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>#HAPPYTAEYANGDAY  Oppa,happy birthday to you, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RT @HoneyBadger10: Panthers in the super bowl....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sorry my Twitter keeps posting my retweets a m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Heart attack causes and symptoms are different...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>780</th>\n",
              "      <td>New Project For NLex Please @DreamscapePH @abs...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>781</th>\n",
              "      <td>Actor DiCaprio joins growing movement to dives...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>782</th>\n",
              "      <td>Just overheard 'looping in' 'reaching out' and...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>783</th>\n",
              "      <td>Photoshoot time! #music #band #photoshootpic.t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>784</th>\n",
              "      <td>Tony Starks N Peanut....Destiny.mp3 by tinomac...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>785 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-661ef3e9-493b-41b8-8ad3-a5f1d8138e1b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-661ef3e9-493b-41b8-8ad3-a5f1d8138e1b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-661ef3e9-493b-41b8-8ad3-a5f1d8138e1b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "sns.countplot(x = train_data[\"Type\"], data = train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "QvSk6HWuIXTt",
        "outputId": "2b17e22f-b151-410b-9c17-d9df135a8c4b"
      },
      "id": "QvSk6HWuIXTt",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='Type', ylabel='count'>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.models import XLMR_BASE_ENCODER\n",
        "from sklearn.model_selection import train_test_split\n",
        "import copy\n",
        "\n",
        "# Split the data into training and testing sets with a 70/30 split\n",
        "train_df, val_df = train_test_split(train_data, test_size=0.2, random_state=42)\n",
        "\n",
        "train_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "rztlRmHJRHro",
        "outputId": "861a0d1e-5523-489a-a4e8-b811fe974c8d"
      },
      "id": "rztlRmHJRHro",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   Tweet  Type\n",
              "1891   Guys! Check out my playlist and new single #DU...   0.0\n",
              "2996   #StopPoliceViolence #StopPoliceBrutality #Stop...   1.0\n",
              "7341            Biology exam went better than I expected   0.0\n",
              "12802  We are proud to be part of this study!https://...   0.0\n",
              "4043   IBM's optical storage is 50 times faster than ...   0.0\n",
              "...                                                  ...   ...\n",
              "5191   The amended #aqabiology specificationpic.twitt...   0.0\n",
              "13418  We fail in people management when we do only I...   0.0\n",
              "5390   #TrumpSlide coming to restore America! I can't...   1.0\n",
              "860    '@johncardillo @realDonaldTrump https://t.co/I...   1.0\n",
              "7270   Spotify Has 20 Million Paid Subscribers http:/...   1.0\n",
              "\n",
              "[11919 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-676671cf-df32-4257-bf73-b01f59c0290d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1891</th>\n",
              "      <td>Guys! Check out my playlist and new single #DU...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2996</th>\n",
              "      <td>#StopPoliceViolence #StopPoliceBrutality #Stop...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7341</th>\n",
              "      <td>Biology exam went better than I expected</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12802</th>\n",
              "      <td>We are proud to be part of this study!https://...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4043</th>\n",
              "      <td>IBM's optical storage is 50 times faster than ...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5191</th>\n",
              "      <td>The amended #aqabiology specificationpic.twitt...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13418</th>\n",
              "      <td>We fail in people management when we do only I...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5390</th>\n",
              "      <td>#TrumpSlide coming to restore America! I can't...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>860</th>\n",
              "      <td>'@johncardillo @realDonaldTrump https://t.co/I...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7270</th>\n",
              "      <td>Spotify Has 20 Million Paid Subscribers http:/...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11919 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-676671cf-df32-4257-bf73-b01f59c0290d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-676671cf-df32-4257-bf73-b01f59c0290d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-676671cf-df32-4257-bf73-b01f59c0290d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.auroria.io/nlp-disaster-tweet-text-classification-roberta-pytorch/\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "import string\n",
        "\n",
        "class TweetDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer):\n",
        "        texts = dataframe.Tweet.values.tolist()\n",
        "\n",
        "        texts = [self._preprocess(text) for text in texts]\n",
        "\n",
        "        self._print_random_samples(texts)\n",
        "\n",
        "        self.texts = [tokenizer(text, padding='max_length',\n",
        "                                max_length=150,\n",
        "                                truncation=True,\n",
        "                                return_tensors=\"pt\")\n",
        "                      for text in texts]\n",
        "\n",
        "        if 'Type' in dataframe:\n",
        "            classes = dataframe.Type.values.tolist()\n",
        "            self.labels = classes\n",
        "\n",
        "    def _print_random_samples(self, texts):\n",
        "        np.random.seed(42)\n",
        "        random_entries = np.random.randint(0, len(texts), 5)\n",
        "\n",
        "        for i in random_entries:\n",
        "            print(f\"Entry {i}: {texts[i]}\")\n",
        "\n",
        "        print()\n",
        "\n",
        "    def _preprocess(self, text):\n",
        "        text = self._remove_amp(text)\n",
        "        # text = self._remove_links(text)\n",
        "        # text = self._remove_hashes(text)\n",
        "        # text = self._remove_retweets(text)\n",
        "        # text = self._remove_mentions(text)\n",
        "        text = self._remove_multiple_spaces(text)\n",
        "\n",
        "        #text = self._lowercase(text)\n",
        "        text = self._remove_punctuation(text)\n",
        "        text = self._remove_numbers(text)\n",
        "\n",
        "        text_tokens = self._tokenize(text)\n",
        "        text_tokens = self._stopword_filtering(text_tokens)\n",
        "        text_tokens = self._stemming(text_tokens)\n",
        "        text = self._stitch_text_tokens_together(text_tokens)\n",
        "\n",
        "        return text.strip()\n",
        "\n",
        "\n",
        "    def _remove_amp(self, text):\n",
        "        return text.replace(\"&amp;\", \" \")\n",
        "\n",
        "    def _remove_mentions(self, text):\n",
        "        return re.sub(r'(@.*?)[\\s]', ' ', text)\n",
        "    \n",
        "    def _remove_multiple_spaces(self, text):\n",
        "        return re.sub(r'\\s+', ' ', text)\n",
        "\n",
        "    def _remove_retweets(self, text):\n",
        "        return re.sub(r'^RT[\\s]+', ' ', text)\n",
        "\n",
        "    def _remove_links(self, text):\n",
        "        return re.sub(r'https?:\\/\\/[^\\s\\n\\r]+', ' ', text)\n",
        "\n",
        "    def _remove_hashes(self, text):\n",
        "        return re.sub(r'#', ' ', text)\n",
        "\n",
        "    def _stitch_text_tokens_together(self, text_tokens):\n",
        "        return \" \".join(text_tokens)\n",
        "\n",
        "    def _tokenize(self, text):\n",
        "        return nltk.word_tokenize(text, language=\"english\")\n",
        "\n",
        "    def _stopword_filtering(self, text_tokens):\n",
        "        stop_words = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "        return [token for token in text_tokens if token not in stop_words]\n",
        "\n",
        "    def _stemming(self, text_tokens):\n",
        "        porter = nltk.stem.porter.PorterStemmer()\n",
        "        return [porter.stem(token) for token in text_tokens]\n",
        "\n",
        "    def _remove_numbers(self, text):\n",
        "        return re.sub(r'\\d+', ' ', text)\n",
        "\n",
        "    def _lowercase(self, text):\n",
        "        return text.lower()\n",
        "\n",
        "    def _remove_punctuation(self, text):\n",
        "        return ''.join(character for character in text if character not in string.punctuation)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "\n",
        "        label = -1\n",
        "        if hasattr(self, 'labels'):\n",
        "            label = self.labels[idx]\n",
        "\n",
        "        return text, label"
      ],
      "metadata": {
        "id": "b2VvFlItZvQ0"
      },
      "id": "b2VvFlItZvQ0",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model\n",
        "from torch import nn\n",
        "\n",
        "class TweetClassifier(nn.Module):\n",
        "    def __init__(self, base_model):\n",
        "        super(TweetClassifier, self).__init__()\n",
        "\n",
        "        self.bert = base_model\n",
        "        self.fc1 = nn.Linear(768, 32)\n",
        "        self.fc2 = nn.Linear(32, 1)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        bert_out = self.bert(input_ids=input_ids,\n",
        "                             attention_mask=attention_mask)[0][:, 0]\n",
        "        x = self.fc1(bert_out)\n",
        "        x = self.relu(x)\n",
        "        \n",
        "        x = self.fc2(x)\n",
        "        x = self.sigmoid(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "1BT6aasTKgvW"
      },
      "id": "1BT6aasTKgvW",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.optim import Adam\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train(model, train_dataloader, val_dataloader, learning_rate, epochs):\n",
        "    best_val_loss = float('inf')\n",
        "    early_stopping_threshold_count = 5\n",
        "    \n",
        "    \n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    model = model.to(device)\n",
        "    criterion = criterion.to(device)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_acc_train = 0\n",
        "        total_loss_train = 0\n",
        "        \n",
        "        model.train()\n",
        "        \n",
        "        for train_input, train_label in tqdm(train_dataloader):\n",
        "            attention_mask = train_input['attention_mask'].to(device)\n",
        "            input_ids = train_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "            train_label = train_label.to(device)\n",
        "\n",
        "            output = model(input_ids, attention_mask)\n",
        "\n",
        "            loss = criterion(output, train_label.float().unsqueeze(1))\n",
        "\n",
        "            total_loss_train += loss.item()\n",
        "\n",
        "            acc = ((output >= 0.5).int() == train_label.unsqueeze(1)).sum().item()\n",
        "            total_acc_train += acc\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            total_acc_val = 0\n",
        "            total_loss_val = 0\n",
        "            \n",
        "            model.eval()\n",
        "            \n",
        "            for val_input, val_label in tqdm(val_dataloader):\n",
        "                attention_mask = val_input['attention_mask'].to(device)\n",
        "                input_ids = val_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "                val_label = val_label.to(device)\n",
        "\n",
        "                output = model(input_ids, attention_mask)\n",
        "\n",
        "                loss = criterion(output, val_label.float().unsqueeze(1))\n",
        "\n",
        "                total_loss_val += loss.item()\n",
        "\n",
        "                acc = ((output >= 0.5).int() == val_label.unsqueeze(1)).sum().item()\n",
        "                total_acc_val += acc\n",
        "            \n",
        "            print(f'Epochs: {epoch + 1} '\n",
        "                  f'| Train Loss: {total_loss_train / len(train_dataloader): .3f} '\n",
        "                  f'| Train Accuracy: {total_acc_train / (len(train_dataloader.dataset)): .3f} '\n",
        "                  f'| Val Loss: {total_loss_val / len(val_dataloader): .3f} '\n",
        "                  f'| Val Accuracy: {total_acc_val / len(val_dataloader.dataset): .3f}')\n",
        "            \n",
        "            if best_val_loss > total_loss_val:\n",
        "                best_val_loss = total_loss_val\n",
        "                torch.save(model, f\"best_model.pt\")\n",
        "                print(\"Saved model\")\n",
        "                early_stopping_threshold_count = 0\n",
        "            else:\n",
        "                early_stopping_threshold_count += 1\n",
        "                \n",
        "            if early_stopping_threshold_count >= 1:\n",
        "                print(\"Early stopping\")\n",
        "                break"
      ],
      "metadata": {
        "id": "eqaDCA4xa-gv"
      },
      "id": "eqaDCA4xa-gv",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "text = \"This is a sentence. This is another sentence.\"\n",
        "sentences = sent_tokenize(text)\n",
        "print(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4WLinxtcAou",
        "outputId": "32815828-a35e-4c6c-905b-4c3285a4f3e1"
      },
      "id": "m4WLinxtcAou",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['This is a sentence.', 'This is another sentence.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnFSk1OlgWwc",
        "outputId": "28395d9c-def4-456a-f06a-204a57f7823c"
      },
      "id": "lnFSk1OlgWwc",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Mar 24 07:49:54 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   29C    P0    42W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "\n",
        "batch_size = 32\n",
        "    \n",
        "BERT_MODEL = \"roberta-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL)\n",
        "base_model = AutoModel.from_pretrained(BERT_MODEL)\n",
        "\n",
        "train_dataloader = DataLoader(TweetDataset(train_df, tokenizer), batch_size=batch_size, shuffle=True, num_workers=12)\n",
        "val_dataloader = DataLoader(TweetDataset(val_df, tokenizer), batch_size=batch_size, num_workers=12)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hb_bnEGxbO2u",
        "outputId": "3b25f641-2d89-4bb6-e296-7074724342ab"
      },
      "id": "hb_bnEGxbO2u",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entry 7270: yeah stripe sock\n",
            "Entry 860: ali boom trump eras anoth piec obama fail legaci httpstcopwdtyvu li httpstcoazgklp tbi\n",
            "Entry 5390: lee amend can stop affh put washington bureaucrat charg local govern httpnatlrewyj yh\n",
            "Entry 5191: now play metro boomin ft drake offset no complaint gt httpstcoemx jgtv v\n",
            "Entry 11284: andri satellit imageri suggest north korea prepar submarin missil test httpstcowzli dsetb httpstcomrooqj ti\n",
            "\n",
            "Entry 860: miss httpstwittercomptrcsrfcstatu …\n",
            "Entry 1294: start record label httpstcopv qnwte via musicindustryu rt\n",
            "Entry 1130: mom told u wake like time your still lay suddenli come roompictwittercomzvgcrm dca\n",
            "Entry 1095: for talk much suck easili handl berni sander she done trump gop candid couldnt\n",
            "Entry 1638: think get new tire summer we lot differ rebat go right stop expir\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for train_input, train_label in (train_dataloader):\n",
        "    print(\"x:\", train_input, \"y:\", train_label)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZaaSMUHlW5P",
        "outputId": "0495e5eb-8310-4a82-cd89-84e88ec61d7c"
      },
      "id": "9ZaaSMUHlW5P",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x: {'input_ids': tensor([[[    0, 24973,   101,  ...,     1,     1,     1]],\n",
            "\n",
            "        [[    0,   415,   513,  ...,     1,     1,     1]],\n",
            "\n",
            "        [[    0,  1916,  3153,  ...,     1,     1,     1]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[    0, 18605,  2458,  ...,     1,     1,     1]],\n",
            "\n",
            "        [[    0,  8628,  6374,  ...,     1,     1,     1]],\n",
            "\n",
            "        [[    0, 11762,  1594,  ...,     1,     1,     1]]]), 'attention_mask': tensor([[[1, 1, 1,  ..., 0, 0, 0]],\n",
            "\n",
            "        [[1, 1, 1,  ..., 0, 0, 0]],\n",
            "\n",
            "        [[1, 1, 1,  ..., 0, 0, 0]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[1, 1, 1,  ..., 0, 0, 0]],\n",
            "\n",
            "        [[1, 1, 1,  ..., 0, 0, 0]],\n",
            "\n",
            "        [[1, 1, 1,  ..., 0, 0, 0]]])} y: tensor([0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
            "        1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1.],\n",
            "       dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = TweetClassifier(base_model)\n",
        "\n",
        "\n",
        "learning_rate = 1e-5\n",
        "epochs = 50\n",
        "train(model, train_dataloader, val_dataloader, learning_rate, epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "FGB7oZsolUHg",
        "outputId": "4b21dbd4-4aa3-42bd-fa7c-5fc4599313a0"
      },
      "id": "FGB7oZsolUHg",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 64/373 [00:15<01:13,  4.23it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-707bc3055fe4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-9ebde829e5b6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, val_dataloader, learning_rate, epochs)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mtotal_acc_train\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[0;32m--> 488\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    489\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "okQ9yzkfKijt"
      },
      "id": "okQ9yzkfKijt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1OgKLYbtKjcy"
      },
      "id": "1OgKLYbtKjcy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "450bd428",
      "metadata": {
        "id": "450bd428"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class TwitterSpamDetector(nn.Module):\n",
        "    def __init__(self, num_tokens, emb_size, num_heads, hidden_size, num_layers, dropout_prob, num_following, num_followers, num_actions):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding(num_tokens, emb_size)\n",
        "        \n",
        "        # Transformer encoder\n",
        "        self.encoder_layer = nn.TransformerEncoderLayer(emb_size, num_heads, hidden_size, dropout_prob)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers)\n",
        "        \n",
        "        # MLP layers\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(emb_size + num_following + num_followers + num_actions + 1, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 2)\n",
        "        )\n",
        "\n",
        "        self.num_following = num_following\n",
        "        self.num_followers = num_followers\n",
        "        self.num_actions = num_actions\n",
        "        \n",
        "    def forward(self, x, following, followers, actions, is_retweet):\n",
        "        # Encode input sequence with Transformer\n",
        "        x = self.embedding(x)\n",
        "        x = self.transformer_encoder(x)\n",
        "\n",
        "        # Concatenate normalized input values\n",
        "        following_norm = following.float()\n",
        "        followers_norm = followers.float()\n",
        "        actions_norm = actions.float()\n",
        "        is_retweet = is_retweet.float()\n",
        "        input_vec = torch.cat([x.mean(dim=1), following_norm.unsqueeze(1), followers_norm.unsqueeze(1), actions_norm.unsqueeze(1), is_retweet.unsqueeze(1)], dim=1)\n",
        "\n",
        "        # Pass through MLP layers\n",
        "        y = self.mlp(input_vec)\n",
        "\n",
        "        return y\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}